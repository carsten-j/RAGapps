{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens, Token Id's, Tokenizer, and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokens\n",
    "* __Definition__ : A token is a piece of text that is treated as a single unit by a language model.\n",
    "* __Examples__ : Tokens can be individual words, word segments, punctuation marks, or special markers (like [CLS] or [SEP] in some model architectures).\n",
    "* __Purpose__ : Language models work fundamentally on sequences of tokens. The first step in processing text is always tokenization‚Äîsplitting text into tokens that the model ‚Äúunderstands.‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Token Id's\n",
    "* __Definition__: Each token has a unique id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Tokenizer\n",
    "* __Definition__ : A tokenizer is a function (or a class) that takes raw text (a string) and outputs a list of tokens or numerical IDs representing those tokens.\n",
    "* __Mechanism__ : Different tokenizers use different approaches:\n",
    "  * __Word-based tokenizers__ : The text is split on spaces and punctuation.\n",
    "  * __Subword/BPE (Byte-Pair Encoding) tokenizers__ : The text is segmented into frequent subwords. For example, ‚Äúembedding‚Äù might be split into ‚Äúem‚Äù, ‚Äúbed‚Äù, and ‚Äúding.‚Äù\n",
    "  * __Character-based tokenizers__ : Every single character may become a token.\n",
    "* __Output__ : Typically, a tokenizer maps tokens to integer indices (IDs). For example, the word ‚ÄúHello‚Äù might be token ID 440 in a certain vocabulary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Embeddings\n",
    "\n",
    "* __Definition__ : The concept of converting data into a vector format is often referred to as embedding. An embedding is a dense numerical vector that captures semantic or contextual information about a token (or an entire sequence).\n",
    "* __Model Output__ : When you pass your tokenized input into a language model (e.g., BERT, GPT), the first layer of the model converts each token ID into an embedding, which is typically a vector of floating-point numbers.\n",
    "* __Dimension__ : Embeddings often have dimensions in the hundreds or even thousands (e.g., 768 or 1024).\n",
    "* __Note__ : It‚Äôs important to note that different data formats require distinct\n",
    "embedding models. For example, an embedding model designed for text would not\n",
    "be suitable for embedding image data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vocabulary\n",
    "\n",
    "ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Putting It All Together\n",
    "You provide raw text (e.g., \"Hello, this is a test.\").\n",
    "The tokenizer splits this text into tokens and assigns IDs (e.g., [101, 7592, 1010, 2023, ...] for a BERT-based model).\n",
    "The model takes these token IDs and looks up or learns an corresponding embedding vector for each token.\n",
    "Higher layers of the model transform or refine these embeddings. Ultimately, these vectors are used in tasks such as classification, language generation, or other NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens and Tokenizers in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the \"Fast\" postfix to the BertTokenizer. This implies that the underlying implementation is based on Rust and not Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"biker biked a long bike tour\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer(text)\n",
    "print(\"Encoded text:\", encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_string = tokenizer.decode(encoded[\"input_ids\"], skip_special_tokens=True)\n",
    "print(\"Decoded text:\", decoded_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we have 9 tokens and only 6 words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tokens_and_ids(encoded):\n",
    "    # 1. Convert the input_ids tensor to a list of token IDs\n",
    "    input_ids = encoded[\"input_ids\"]\n",
    "\n",
    "    # 2. Convert each token ID back to its corresponding token\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # 3. Print the tokens with their IDs\n",
    "    for token, token_id in zip(tokens, input_ids):\n",
    "        print(f\"Token: {token}\\tID: {token_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tokens_and_ids(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just one example of a tokenizer. \n",
    "\n",
    "Can you think of more ways to split a text into tokens?\n",
    "\n",
    "Think about pros and cons for your proposed tokenizer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "\n",
    "* Word Tokenization\n",
    "* Character Tokenization\n",
    "* Subword Tokenization\n",
    "    * Byte Pair Encoding (BPE)\n",
    "    * WordPiece\n",
    "    * SentencePiece\n",
    "    * Unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as I know OpenAI are using the BPE tokenizer or some variant. It is not that difficult to implement a working version of [BPE](https://sebastianraschka.com/blog/2025/bpe-from-scratch.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember to check that your choice of tokenizer can handle expected input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy = tokenizer(\"I feel üòä today!\")\n",
    "print_tokens_and_ids(happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad = tokenizer(\"I feel üò¢ today!\")\n",
    "print_tokens_and_ids(sad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This advice most likely also applies to other languages than English!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding are not just embedding. There are a least 2 different kinds of embeddings:\n",
    "\n",
    "* sentence/chunks/documents embeddings and\n",
    "* word embeddings\n",
    "\n",
    "In a RAG application we will be searching our index for sentences similar to the users query. Hence sentence embeddings are more likely to be succesfull. \n",
    "\n",
    "For LLM base models we are simply trying to predict the next word (=token), so here word embedding are commonly used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model\n",
    "\n",
    "Working with sentence embedding seems easier than word embedding. The following code is quite low level since we want to use the same model for both sentence and word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._first_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer consists of multiple stack modules. Tokens are an input\n",
    "# of the first one, so we can ignore the rest.\n",
    "first_module = model._first_module()\n",
    "\n",
    "tokenizer = first_module.tokenizer\n",
    "embeddings = first_module.auto_model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sentence = \"vector search optimization\"\n",
    "second_sentence = \"how do I use vector search optimization\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Tokenize both texts\n",
    "    first_tokens = model.tokenize([first_sentence])\n",
    "    second_tokens = model.tokenize([second_sentence])\n",
    "\n",
    "    # Get the corresponding embeddings\n",
    "    first_embeddings = embeddings.word_embeddings(first_tokens[\"input_ids\"].to(device))\n",
    "    second_embeddings = embeddings.word_embeddings(\n",
    "        second_tokens[\"input_ids\"].to(device)\n",
    "    )\n",
    "\n",
    "first_embeddings.shape, second_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tokens[\"input_ids\"], second_tokens[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_embeddings.shape, second_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = (\n",
    "    util.cos_sim(first_embeddings.squeeze(), second_embeddings.squeeze()).cpu().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    distances,\n",
    "    x=model.tokenizer.convert_ids_to_tokens(second_tokens[\"input_ids\"][0]),\n",
    "    y=model.tokenizer.convert_ids_to_tokens(first_tokens[\"input_ids\"][0]),\n",
    "    text_auto=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sentence_embedding = model.encode(first_sentence)\n",
    "second_sentence_embedding = model.encode(second_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = (\n",
    "    util.cos_sim(\n",
    "        first_sentence_embedding.squeeze(), second_sentence_embedding.squeeze()\n",
    "    )\n",
    "    .cpu()\n",
    "    .numpy()\n",
    ")\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the model embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = embeddings.word_embeddings.weight.detach().cpu().numpy()\n",
    "token_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = tokenizer.get_vocab()\n",
    "sorted_vocabulary = sorted(\n",
    "    vocabulary.items(),\n",
    "    key=lambda x: x[1],  # uses the value of the dictionary entry\n",
    ")\n",
    "sorted_tokens = [token for token, _ in sorted_vocabulary]\n",
    "random.choices(sorted_tokens, k=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, metric=\"cosine\", random_state=42)\n",
    "tsne_embeddings_2d = tsne.fit_transform(token_embeddings)\n",
    "tsne_embeddings_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_colors = []\n",
    "for token in sorted_tokens:\n",
    "    if token[0] == \"[\" and token[-1] == \"]\":\n",
    "        token_colors.append(\"red\")\n",
    "    elif token.startswith(\"##\"):\n",
    "        token_colors.append(\"blue\")\n",
    "    else:\n",
    "        token_colors.append(\"green\")\n",
    "\n",
    "\n",
    "scatter = go.Scattergl(\n",
    "    x=tsne_embeddings_2d[:, 0],\n",
    "    y=tsne_embeddings_2d[:, 1],\n",
    "    text=sorted_tokens,\n",
    "    marker=dict(color=token_colors, size=3),\n",
    "    mode=\"markers\",\n",
    "    name=\"Token embeddings\",\n",
    ")\n",
    "\n",
    "fig = go.FigureWidget(\n",
    "    data=[scatter],\n",
    "    layout=dict(\n",
    "        width=600,\n",
    "        height=900,\n",
    "        margin=dict(l=0, r=0),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace these with the paths or filenames of your four images\n",
    "image_paths = [\n",
    "    \"images/banana.jpg\",\n",
    "    \"images/bananas.jpg\",\n",
    "    \"images/different_bananas.jpg\",\n",
    "    \"images/pizza.jpg\",\n",
    "]\n",
    "\n",
    "# Create a figure with 1 row and 4 columns\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(12, 3))\n",
    "\n",
    "# Load each image and show it in a separate subplot\n",
    "for i, path in enumerate(image_paths):\n",
    "    # Read the .jpg image using matplotlib.image\n",
    "    img = mpimg.imread(path)\n",
    "\n",
    "    # Display the image\n",
    "    axes[i].imshow(img)\n",
    "\n",
    "    # Optionally, turn off the axis ticks/spines\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"clip-ViT-L-14\")\n",
    "banana_embeddings = model.encode(Image.open(\"images/banana.jpg\"))\n",
    "\n",
    "print(len(banana_embeddings))  # Dimension of embeddings 768\n",
    "print(banana_embeddings[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bananas_embeddings = model.encode(Image.open(\"images/bananas.jpg\"))\n",
    "different_bananas_embeddings = model.encode(Image.open(\"images/different_bananas.jpg\"))\n",
    "pizza_embeddings = model.encode(Image.open(\"images/pizza.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.array(\n",
    "    [\n",
    "        banana_embeddings,\n",
    "        bananas_embeddings,\n",
    "        different_bananas_embeddings,\n",
    "        pizza_embeddings,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"banana\", \"bananas\", \"different bananas\", \"pizza\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    similarity_matrix,\n",
    "    x=labels,\n",
    "    y=labels,\n",
    "    text_auto=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
